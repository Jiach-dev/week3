{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7f59e66-be5c-40da-b9bf-53e0487d192a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Read new data from Bronze\n",
    "bronze_df = spark.table(\"bronze_nyc_taxi\").filter(\"processed_date IS NULL\")\n",
    "\n",
    "# Data cleaning and transformations\n",
    "silver_df = bronze_df.withColumn(\"trip_duration_min\", \n",
    "                (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\"))/60) \\\n",
    "             .withColumn(\"is_airport_pickup\", col(\"PULocationID\").isin([1, 132, 138])) \\\n",
    "             .withColumn(\"time_of_day_slot\", \n",
    "                when(hour(\"tpep_pickup_datetime\").between(5,11), \"Morning\")\n",
    "                .when(hour(\"tpep_pickup_datetime\").between(12,16), \"Afternoon\")\n",
    "                .when(hour(\"tpep_pickup_datetime\").between(17,20), \"Evening\")\n",
    "                .otherwise(\"Night\")) \\\n",
    "             .withColumn(\"trip_id\", sha2(concat_ws(\"||\", \n",
    "                col(\"VendorID\"), \n",
    "                col(\"tpep_pickup_datetime\"), \n",
    "                col(\"tpep_dropoff_datetime\")), 256))\n",
    "\n",
    "# Data quality checks\n",
    "assert bronze_df.filter(\"trip_distance <= 0\").count() == 0, \"Invalid trip distances found\"\n",
    "assert bronze_df.filter(\"fare_amount < 0\").count() == 0, \"Negative fares found\"\n",
    "assert bronze_df.filter(\"tpep_dropoff_datetime <= tpep_pickup_datetime\").count() == 0, \"Invalid time ranges\"\n",
    "\n",
    "# Write to Silver with merge\n",
    "silver_df.createOrReplaceTempView(\"updates\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "  MERGE INTO silver_nyc_taxi target\n",
    "  USING updates source\n",
    "  ON source.trip_id = target.trip_id\n",
    "  WHEN MATCHED AND target.processed_date IS NULL THEN UPDATE SET *\n",
    "  WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "# Mark Bronze records as processed\n",
    "spark.sql(\"\"\"\n",
    "  UPDATE bronze_nyc_taxi\n",
    "  SET processed_date = current_date()\n",
    "  WHERE processed_date IS NULL\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_workflow_transform_to_silver.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}